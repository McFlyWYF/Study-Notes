{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9184e-39, 8.7245e-39, 9.2755e-39],\n",
       "        [8.9082e-39, 9.9184e-39, 8.4490e-39],\n",
       "        [9.6429e-39, 1.0653e-38, 1.0469e-38],\n",
       "        [4.2246e-39, 1.0378e-38, 9.6429e-39],\n",
       "        [9.2755e-39, 1.0928e-38, 9.9184e-39]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5*3矩阵,未初始化\n",
    "x = t.Tensor(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2414, 0.4205, 0.0442],\n",
       "        [0.3144, 0.2890, 0.3438],\n",
       "        [0.4843, 0.6580, 0.2393],\n",
       "        [0.1634, 0.7471, 0.5918],\n",
       "        [0.0745, 0.4044, 0.6408]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [0,1]均匀分布初始化二维数组\n",
    "x = t.rand(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())# x格式，元组格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#列的个数\n",
    "x.size()[1]\n",
    "#或者\n",
    "# x.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4162, 1.0766, 0.9098],\n",
       "        [1.2650, 0.2969, 1.0018],\n",
       "        [1.4333, 0.8003, 0.2979],\n",
       "        [0.9422, 0.9486, 0.7300],\n",
       "        [0.7607, 0.5718, 0.7798]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x+y\n",
    "y = t.rand(5,3)\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4162, 1.0766, 0.9098],\n",
       "        [1.2650, 0.2969, 1.0018],\n",
       "        [1.4333, 0.8003, 0.2979],\n",
       "        [0.9422, 0.9486, 0.7300],\n",
       "        [0.7607, 0.5718, 0.7798]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 或者\n",
    "t.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4162, 1.0766, 0.9098],\n",
       "        [1.2650, 0.2969, 1.0018],\n",
       "        [1.4333, 0.8003, 0.2979],\n",
       "        [0.9422, 0.9486, 0.7300],\n",
       "        [0.7607, 0.5718, 0.7798]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = t.Tensor(5,3)\n",
    "t.add(x,y,out=result)#结果输出到result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1748, 0.6561, 0.8656],\n",
      "        [0.9506, 0.0079, 0.6580],\n",
      "        [0.9490, 0.1423, 0.0586],\n",
      "        [0.7788, 0.2015, 0.1382],\n",
      "        [0.6862, 0.1674, 0.1390]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1748, 0.6561, 0.8656],\n",
       "        [0.9506, 0.0079, 0.6580],\n",
       "        [0.9490, 0.1423, 0.0586],\n",
       "        [0.7788, 0.2015, 0.1382],\n",
       "        [0.6862, 0.1674, 0.1390]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y)\n",
    "y.add(x)# y的内容不变\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4162, 1.0766, 0.9098],\n",
      "        [1.2650, 0.2969, 1.0018],\n",
      "        [1.4333, 0.8003, 0.2979],\n",
      "        [0.9422, 0.9486, 0.7300],\n",
      "        [0.7607, 0.5718, 0.7798]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6576, 1.4971, 0.9540],\n",
       "        [1.5794, 0.5859, 1.3456],\n",
       "        [1.9176, 1.4583, 0.5373],\n",
       "        [1.1055, 1.6957, 1.3219],\n",
       "        [0.8353, 0.9762, 1.4206]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y)\n",
    "y.add_(x)# y的内容改变\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* x.add(y)不会改变x的内容，而x.add_(y)会改变tensor本身，改变x的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2414, 0.4205, 0.0442],\n",
       "        [0.3144, 0.2890, 0.3438],\n",
       "        [0.4843, 0.6580, 0.2393],\n",
       "        [0.1634, 0.7471, 0.5918],\n",
       "        [0.0745, 0.4044, 0.6408]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4205, 0.2890])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:2,1]# 取第二列第一行和第二行内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建5*5的全1矩阵\n",
    "a = t.ones(5,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3., 3.]])\n",
      "[[3. 3. 3. 3. 3.]\n",
      " [3. 3. 3. 3. 3.]\n",
      " [3. 3. 3. 3. 3.]\n",
      " [3. 3. 3. 3. 3.]\n",
      " [3. 3. 3. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转换为GPU\n",
    "if t.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动微分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variable主要包含三个属性。\n",
    "- `data`：保存Variable所包含的Tensor\n",
    "- `grad`：保存`data`对应的梯度，`grad`也是个Variable，而不是Tensor，它和`data`的形状一样。\n",
    "- `grad_fn`：指向一个`Function`对象，这个`Function`用来反向传播计算输入的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(t.ones(2,2),requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SumBackward0 at 0x213501bfef0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()#反向传播，计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)#梯度是累加的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.data.zero_()#清空操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
       "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
       "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
       "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(t.ones(4,5))\n",
    "y = t.cos(x)\n",
    "x_tensor_cos = t.cos(x.data)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
       "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
       "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403],\n",
       "        [0.5403, 0.5403, 0.5403, 0.5403, 0.5403]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch.nn是神经网络的模块化接口，nn.Module是nn最重要的类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 前向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):#可学习参数放在__init__中\n",
    "        super(Net,self).__init__()#父类构造函数\n",
    "        # 或者\n",
    "#         nn.Module.__init__(self)\n",
    "        # 卷积层‘1’表示输入图片为单通道，‘6’表示输出通道数，‘5’表示卷积核为5*5\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        #卷积层\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        #全连接层,y = Wx + b\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #卷积 -> 激活 -> 池化\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        # reshape ,'-1'表示自适应\n",
    "        x = x.view(x.size()[0],-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[ 0.1081, -0.0247, -0.1457,  0.1205, -0.0554],\n",
       "           [ 0.0122,  0.1828, -0.0993, -0.0645, -0.0842],\n",
       "           [-0.0605, -0.0757,  0.0118, -0.0595,  0.0059],\n",
       "           [ 0.0083, -0.0470, -0.0855,  0.0840,  0.1677],\n",
       "           [-0.0418,  0.1785, -0.1107,  0.0905, -0.1713]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0337, -0.1925,  0.1757,  0.0767,  0.0545],\n",
       "           [ 0.0365,  0.1047, -0.1709, -0.1770,  0.0835],\n",
       "           [ 0.0134,  0.0974, -0.1600,  0.0434, -0.1616],\n",
       "           [-0.1340, -0.0575, -0.1710,  0.1886,  0.1871],\n",
       "           [ 0.0343, -0.1518, -0.1999, -0.0287, -0.0518]]],\n",
       " \n",
       " \n",
       "         [[[-0.0337, -0.0964,  0.1993, -0.1527,  0.0555],\n",
       "           [ 0.1826,  0.0185, -0.0563, -0.0519, -0.0367],\n",
       "           [ 0.1418, -0.0371, -0.0579, -0.0549,  0.1910],\n",
       "           [-0.1177, -0.1529,  0.0803,  0.0980,  0.1787],\n",
       "           [-0.1253, -0.0448,  0.0878, -0.0182, -0.1076]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1033,  0.0135,  0.0328,  0.1460, -0.1021],\n",
       "           [-0.1678,  0.0069, -0.0643,  0.1659, -0.0842],\n",
       "           [-0.1407,  0.0911,  0.1261,  0.0956, -0.1608],\n",
       "           [ 0.0862, -0.0232,  0.0205,  0.0633,  0.1593],\n",
       "           [-0.1807, -0.0370,  0.1878, -0.1558, -0.0105]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0141, -0.0334, -0.1764,  0.1079,  0.0100],\n",
       "           [ 0.1534, -0.0840,  0.0877,  0.1688,  0.0011],\n",
       "           [ 0.1717,  0.1127, -0.0782,  0.1210, -0.0389],\n",
       "           [ 0.0209,  0.0404, -0.1112,  0.0926, -0.1057],\n",
       "           [-0.1977,  0.1584,  0.0777, -0.0417,  0.1548]]],\n",
       " \n",
       " \n",
       "         [[[-0.1976, -0.1781, -0.0884,  0.0573, -0.0826],\n",
       "           [-0.1512,  0.1856, -0.1249, -0.1312, -0.1460],\n",
       "           [ 0.1768, -0.1561,  0.1952, -0.1066, -0.0053],\n",
       "           [-0.1436, -0.0483, -0.0346,  0.1348, -0.0804],\n",
       "           [-0.1773,  0.1234,  0.1401, -0.1739,  0.0587]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1037,  0.0368, -0.1458,  0.0366,  0.1705, -0.0278],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 4.6954e-02, -4.0962e-02, -5.2463e-02, -6.1234e-02,  2.7974e-02],\n",
       "           [ 1.8478e-02, -3.6949e-02,  3.4784e-02, -5.5471e-02, -7.5349e-02],\n",
       "           [-3.5069e-03, -1.6420e-02,  5.4854e-02, -1.5587e-03, -4.8445e-02],\n",
       "           [ 4.7985e-02, -7.1744e-02, -1.5567e-02, -6.4578e-02,  5.0951e-03],\n",
       "           [-5.2126e-02, -6.8099e-02, -7.1463e-02,  4.7309e-02, -2.5492e-02]],\n",
       " \n",
       "          [[-2.1512e-02,  2.4727e-02,  5.6225e-02, -4.9258e-02, -8.0076e-02],\n",
       "           [-7.2627e-02, -7.3262e-02,  8.0476e-02,  4.1878e-02,  4.6167e-02],\n",
       "           [-8.2895e-03,  7.1701e-02,  4.9497e-02, -2.6427e-02, -5.2965e-02],\n",
       "           [ 5.0685e-02,  4.2653e-02, -4.5496e-02, -2.2437e-02,  4.4030e-02],\n",
       "           [-4.7349e-02, -6.1435e-02,  4.1683e-02, -4.0331e-03,  7.1360e-02]],\n",
       " \n",
       "          [[-3.8634e-02,  2.6057e-02,  2.1833e-02,  2.8003e-02, -3.2343e-02],\n",
       "           [ 6.3496e-02,  4.4827e-02, -5.5772e-02,  4.3053e-03, -6.8372e-02],\n",
       "           [ 6.3123e-02, -6.8923e-02, -4.4329e-02, -2.2119e-02,  6.5285e-02],\n",
       "           [-5.4622e-02,  2.0216e-02, -4.4284e-02, -1.9155e-02, -5.6971e-02],\n",
       "           [ 6.1660e-02, -7.8474e-02, -2.5183e-02,  7.0031e-02,  2.5680e-02]],\n",
       " \n",
       "          [[-7.1917e-02, -2.6576e-02,  2.0852e-02,  1.7914e-02, -2.4641e-02],\n",
       "           [ 6.0383e-02, -5.0656e-02,  5.3408e-02, -2.8482e-02,  8.1596e-02],\n",
       "           [ 6.9785e-02,  1.2855e-02,  4.5704e-02,  1.3142e-02,  1.0272e-02],\n",
       "           [ 7.9517e-02,  2.1462e-02,  5.4536e-02, -4.4721e-03,  2.0215e-02],\n",
       "           [-6.9499e-02, -7.1320e-02, -8.0803e-02,  4.9796e-03, -2.2998e-02]],\n",
       " \n",
       "          [[-4.9210e-02,  7.0594e-02,  3.3361e-02, -2.0021e-02,  5.3131e-02],\n",
       "           [ 6.5727e-02,  1.5085e-02,  2.9663e-02, -5.3663e-03,  7.6878e-02],\n",
       "           [-3.3661e-03,  2.9259e-02,  2.0669e-02,  3.4690e-02,  6.7329e-02],\n",
       "           [ 1.9157e-03,  4.5538e-02, -6.0900e-02,  3.5815e-02,  4.7426e-03],\n",
       "           [ 7.4928e-02, -3.9049e-03, -5.9101e-02,  3.2150e-02, -2.5740e-02]],\n",
       " \n",
       "          [[ 4.1702e-02,  7.9659e-02, -7.5691e-02,  3.6894e-02, -7.4369e-02],\n",
       "           [ 6.6954e-02,  5.2213e-02,  7.7402e-02, -1.8713e-02,  7.7020e-02],\n",
       "           [-2.2884e-02,  3.1062e-02,  7.8807e-02,  9.8477e-03,  2.2644e-02],\n",
       "           [-4.5216e-02,  5.0509e-02, -2.6139e-02, -2.7647e-02, -4.4558e-04],\n",
       "           [-1.7239e-02,  6.3235e-02,  6.1584e-02, -4.5421e-02, -7.2799e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.1134e-02, -1.5602e-02, -5.1998e-02, -2.5341e-02,  5.4645e-02],\n",
       "           [-1.7875e-02, -6.5505e-02,  3.5597e-02, -7.4037e-02, -6.6012e-02],\n",
       "           [ 7.4332e-02, -5.5227e-02,  1.6657e-02, -3.5264e-02,  6.0251e-02],\n",
       "           [ 5.1826e-02,  6.9425e-02, -7.3952e-02,  1.2222e-02,  2.5774e-02],\n",
       "           [-4.5908e-03,  2.9843e-02,  5.3052e-02, -3.4854e-03,  5.5089e-02]],\n",
       " \n",
       "          [[-5.5730e-02, -4.8600e-03, -3.2196e-02, -2.8786e-02,  5.4819e-02],\n",
       "           [-7.0497e-03, -3.4349e-02, -3.6516e-02,  7.9878e-02, -6.6644e-02],\n",
       "           [-1.9337e-02, -6.5349e-02,  5.3173e-03,  6.4867e-02,  6.2775e-02],\n",
       "           [-3.0177e-02,  7.0343e-02, -7.6149e-04, -5.3511e-02,  6.2994e-02],\n",
       "           [ 2.4378e-03, -6.3085e-02, -5.9956e-02, -2.4832e-03, -4.8729e-02]],\n",
       " \n",
       "          [[ 5.2070e-02, -7.0655e-03, -6.2251e-02, -1.3802e-02, -6.3217e-04],\n",
       "           [-4.1709e-02,  6.5869e-02, -1.2255e-02, -2.7886e-02,  1.3259e-02],\n",
       "           [-1.1290e-03, -6.7226e-02, -6.3320e-03,  8.1562e-02,  4.8284e-02],\n",
       "           [ 4.2745e-02,  6.9199e-02,  4.7332e-02,  6.9356e-02, -3.1174e-02],\n",
       "           [-1.2543e-02, -6.0790e-02, -3.2815e-02,  6.0608e-02,  1.4195e-02]],\n",
       " \n",
       "          [[-5.2850e-02, -7.6798e-02, -7.6174e-02,  5.3711e-02, -2.2349e-02],\n",
       "           [-4.4237e-02, -7.7249e-03, -3.1881e-02, -1.2213e-02,  6.5365e-02],\n",
       "           [-7.1331e-02,  2.4104e-02, -6.2352e-02, -7.2743e-02, -2.9431e-02],\n",
       "           [ 3.2061e-02,  3.8819e-02, -1.9127e-02,  7.5222e-03,  2.4823e-02],\n",
       "           [-8.0357e-03,  5.9388e-03, -3.1044e-02, -4.9078e-02,  7.0070e-02]],\n",
       " \n",
       "          [[-4.3746e-02,  5.0259e-02,  5.6232e-02, -2.8363e-02,  2.9991e-02],\n",
       "           [-4.1710e-02,  6.7755e-02,  1.2466e-02, -3.5182e-02, -4.1142e-02],\n",
       "           [-7.6965e-02,  3.5617e-02, -5.6422e-02, -2.4036e-02, -5.8728e-02],\n",
       "           [-7.8862e-02,  7.3925e-02, -2.1858e-02,  3.2336e-02,  7.9395e-02],\n",
       "           [-2.3902e-02, -2.0236e-02, -8.0890e-02, -7.1139e-02,  7.6833e-02]],\n",
       " \n",
       "          [[-6.8109e-03, -5.0473e-02,  1.2615e-02,  5.3070e-02,  8.1605e-02],\n",
       "           [-1.8589e-02,  6.9664e-02,  5.0920e-03,  4.3951e-02,  7.6422e-02],\n",
       "           [-7.2339e-02, -6.7216e-02, -6.2458e-02, -5.0003e-02,  4.7645e-02],\n",
       "           [-1.2997e-02, -8.4854e-03, -5.5849e-02, -8.3450e-03,  1.8263e-02],\n",
       "           [ 3.3946e-02, -3.4483e-02, -9.2291e-03,  3.1545e-02, -7.5744e-03]]],\n",
       " \n",
       " \n",
       "         [[[-4.0793e-02, -3.4863e-02, -7.0164e-02,  3.2173e-03,  9.0275e-03],\n",
       "           [ 4.7651e-02,  2.0563e-02,  3.5008e-02, -7.9070e-02, -5.7247e-02],\n",
       "           [-1.3027e-02,  1.2432e-02,  3.0489e-02,  4.0106e-02, -3.5452e-02],\n",
       "           [-1.2994e-03,  7.9946e-02,  5.2875e-02, -4.3761e-02,  5.2551e-02],\n",
       "           [-1.9712e-02, -3.1434e-02, -7.1408e-04, -7.3579e-02,  1.4624e-02]],\n",
       " \n",
       "          [[ 7.2427e-02, -1.4813e-02, -6.7487e-02,  1.6651e-02, -2.7344e-02],\n",
       "           [ 5.8707e-02, -2.2631e-03,  3.7690e-02, -9.2602e-03, -4.4152e-02],\n",
       "           [ 1.5425e-03, -2.0399e-02, -7.9156e-02,  2.6868e-02, -1.6808e-02],\n",
       "           [-9.8785e-03, -5.6311e-02, -7.9405e-02,  6.7234e-02,  9.4021e-03],\n",
       "           [ 7.2606e-02, -7.0682e-02,  7.8475e-02,  2.1687e-02,  3.2031e-02]],\n",
       " \n",
       "          [[ 7.4425e-03,  6.5869e-03, -1.6740e-02,  1.1793e-02,  2.7174e-03],\n",
       "           [ 2.6005e-02,  4.9055e-02,  3.0522e-02,  5.0227e-02, -1.1392e-03],\n",
       "           [ 7.1821e-02,  2.6753e-02, -4.4793e-02,  1.7139e-02,  2.9552e-02],\n",
       "           [-7.6332e-03, -1.7315e-02,  2.0970e-02, -6.8311e-02, -2.2827e-03],\n",
       "           [-5.4185e-02,  1.0692e-02, -4.5434e-02,  1.8191e-02, -6.5445e-02]],\n",
       " \n",
       "          [[-2.7173e-03,  7.3290e-02,  6.1882e-02,  1.3473e-02, -2.3037e-02],\n",
       "           [-6.8185e-02, -2.3897e-02,  7.9308e-02,  6.9382e-02, -1.7896e-03],\n",
       "           [ 7.0746e-02, -4.0935e-02, -3.2310e-02, -1.4670e-02, -3.6185e-02],\n",
       "           [ 5.3519e-02, -7.9995e-02,  3.5033e-02, -2.9751e-02,  2.7280e-02],\n",
       "           [-4.1722e-02,  4.0925e-02, -5.7348e-02,  7.9684e-02,  6.7425e-02]],\n",
       " \n",
       "          [[-2.1393e-02,  7.3142e-03, -7.0698e-02,  5.1809e-02, -2.2009e-03],\n",
       "           [ 6.9882e-02,  1.8332e-02, -3.9747e-02,  7.6846e-02, -5.9420e-02],\n",
       "           [ 6.8788e-02, -7.6181e-02, -3.9881e-02, -8.8291e-03,  2.2511e-02],\n",
       "           [-6.2438e-02, -3.7461e-02, -3.4314e-03,  2.0725e-02, -2.1056e-02],\n",
       "           [ 7.4628e-02,  4.7756e-02,  2.1120e-02,  5.0879e-03,  1.6458e-02]],\n",
       " \n",
       "          [[-7.1879e-02, -7.2673e-02, -3.5547e-02, -2.1705e-02,  1.0874e-04],\n",
       "           [-7.9219e-02,  7.0908e-02, -5.7689e-02,  6.6201e-02,  2.0846e-02],\n",
       "           [ 4.8821e-02, -1.4137e-02, -1.1454e-02, -5.5496e-03, -6.3216e-02],\n",
       "           [ 5.7942e-02,  1.4412e-02,  6.2882e-02, -7.2592e-02,  5.2674e-02],\n",
       "           [-7.2753e-02, -3.5717e-02,  2.6690e-02, -2.1932e-02, -7.6724e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-7.3875e-02,  7.5261e-02, -8.4596e-03,  1.3489e-02,  7.0853e-02],\n",
       "           [ 6.8353e-03, -6.8076e-02,  4.2357e-02,  4.0190e-02,  6.5484e-02],\n",
       "           [ 4.6644e-02, -5.4938e-02,  2.3824e-02, -3.3463e-02,  2.3069e-02],\n",
       "           [ 3.2574e-02,  3.5452e-03,  6.6445e-02,  4.9238e-02, -3.5478e-02],\n",
       "           [ 1.3811e-02,  2.6417e-02, -4.8701e-02,  2.5930e-02, -4.0623e-02]],\n",
       " \n",
       "          [[ 2.5125e-02,  7.4607e-02, -6.9216e-02, -5.3812e-02, -2.1385e-02],\n",
       "           [-2.2337e-02,  2.6150e-02, -4.7069e-02,  2.8760e-02, -4.4158e-02],\n",
       "           [-3.7541e-02,  7.8226e-02, -1.7349e-02, -2.4616e-02, -7.6563e-02],\n",
       "           [-6.3071e-03, -5.9862e-02,  6.2535e-02,  5.9866e-02, -4.5086e-02],\n",
       "           [-1.5656e-02,  3.6298e-02, -4.0078e-02,  7.0836e-02,  5.0719e-02]],\n",
       " \n",
       "          [[-5.9631e-02, -4.6377e-03,  2.8807e-02,  7.6856e-02, -1.2962e-02],\n",
       "           [ 4.2927e-02, -5.7560e-02,  7.9525e-02, -1.4910e-03, -5.3512e-02],\n",
       "           [ 5.3624e-02,  5.3265e-03, -5.1769e-02,  1.2584e-02, -4.1896e-02],\n",
       "           [-3.2993e-03, -5.4170e-03,  7.3884e-02, -2.1360e-02, -6.0381e-02],\n",
       "           [-3.3390e-03,  3.9082e-02,  3.0429e-02, -3.1565e-02, -7.9066e-02]],\n",
       " \n",
       "          [[-5.3563e-02,  7.3702e-02,  8.1363e-02,  4.0465e-02,  2.1917e-02],\n",
       "           [ 7.2829e-02, -3.6966e-02,  4.1553e-02, -5.8953e-02,  4.4626e-02],\n",
       "           [-1.2751e-02,  2.2702e-02,  5.9605e-02,  4.7782e-02,  5.3875e-02],\n",
       "           [ 1.2813e-02, -4.9120e-02,  1.5086e-02, -8.0435e-02,  4.7126e-02],\n",
       "           [-1.5245e-02, -5.1708e-02, -2.8050e-02, -7.6902e-02, -2.2388e-02]],\n",
       " \n",
       "          [[ 5.8012e-03, -4.0567e-02,  1.9242e-02, -6.5881e-02,  6.2968e-03],\n",
       "           [ 5.5679e-02, -2.0094e-03, -6.3841e-02,  4.1237e-02,  7.3524e-02],\n",
       "           [-7.4473e-03, -7.3510e-02,  5.0818e-02,  6.2620e-02, -7.9252e-02],\n",
       "           [-5.1276e-02,  3.7564e-02, -1.0851e-02, -2.8676e-02, -1.5415e-02],\n",
       "           [ 1.5659e-02,  3.4389e-02,  6.2095e-02,  2.3245e-02, -2.6775e-02]],\n",
       " \n",
       "          [[ 1.1039e-02,  1.3130e-02, -6.3420e-02,  7.4022e-02,  1.2952e-02],\n",
       "           [-6.4312e-02,  4.0900e-02,  2.2304e-02, -2.4761e-02,  5.8417e-02],\n",
       "           [ 6.2580e-03,  2.1450e-02, -3.3706e-05,  2.7999e-02, -3.4212e-02],\n",
       "           [-1.2165e-02,  4.2462e-02, -4.4325e-02,  5.6564e-02, -5.8643e-02],\n",
       "           [-3.8352e-02, -5.1870e-03, -6.2835e-02, -5.6229e-03, -8.2032e-03]]],\n",
       " \n",
       " \n",
       "         [[[-3.9952e-02, -3.6608e-02, -5.7418e-02, -4.6639e-02,  3.2087e-02],\n",
       "           [-6.6988e-02,  1.1532e-02,  3.4054e-02,  6.8264e-02, -2.0366e-02],\n",
       "           [-5.9147e-02, -7.4296e-02, -5.8186e-02, -2.5893e-02, -5.1778e-02],\n",
       "           [ 7.0154e-02, -2.8042e-02, -1.9173e-02,  3.1570e-02, -4.2937e-02],\n",
       "           [-2.0866e-02, -4.1344e-02, -5.0172e-02,  4.0129e-02,  5.0628e-02]],\n",
       " \n",
       "          [[-3.7386e-02,  4.1332e-02, -2.6909e-02,  2.6135e-02,  6.7461e-02],\n",
       "           [-2.1089e-02,  8.6518e-03,  3.9732e-02,  7.6160e-02,  3.4360e-02],\n",
       "           [ 4.3246e-02,  5.0524e-02,  4.8861e-02,  3.7024e-02, -3.8816e-02],\n",
       "           [-1.8871e-02,  5.8327e-02,  8.4416e-03,  8.1408e-02,  1.5658e-02],\n",
       "           [-2.9761e-02,  6.7973e-02,  6.1954e-02, -3.9991e-02,  1.3691e-02]],\n",
       " \n",
       "          [[-5.5587e-02,  1.8157e-02,  7.4723e-02, -6.4377e-02, -3.3699e-02],\n",
       "           [-7.5969e-02,  5.7046e-02,  6.5132e-02, -4.0366e-02,  4.7524e-02],\n",
       "           [-2.1725e-02,  5.7063e-02, -1.7108e-02, -3.2002e-02, -1.1824e-02],\n",
       "           [-5.9654e-02,  7.6201e-02,  6.0833e-02,  5.5309e-02,  4.6880e-02],\n",
       "           [-4.0714e-02,  7.6178e-02, -6.9454e-02, -3.6358e-02,  4.0736e-02]],\n",
       " \n",
       "          [[-4.8273e-02, -7.2657e-02, -5.0603e-02, -2.5461e-02,  4.3579e-02],\n",
       "           [ 5.4656e-02,  1.6426e-02,  3.2837e-02, -5.4052e-02,  6.7898e-02],\n",
       "           [ 1.1298e-02, -8.0861e-02, -4.1951e-02,  7.8996e-02,  4.4139e-02],\n",
       "           [-5.4807e-02,  5.7058e-02, -4.6383e-02, -6.6311e-02, -6.6872e-02],\n",
       "           [ 5.5959e-02,  2.1896e-02, -7.8412e-02, -7.1097e-03, -1.3432e-02]],\n",
       " \n",
       "          [[-4.0675e-02,  7.6050e-02, -4.8018e-02,  5.3219e-02,  5.1361e-02],\n",
       "           [-7.3006e-03, -1.2186e-02,  6.4810e-02,  1.2999e-02, -4.2879e-02],\n",
       "           [ 3.8891e-02,  4.3841e-02,  5.0027e-02,  7.9091e-02, -2.6272e-03],\n",
       "           [ 3.9123e-03,  7.0427e-02,  2.8041e-02, -2.0597e-02, -7.6719e-03],\n",
       "           [-2.4139e-02, -7.1807e-02,  5.4156e-02, -5.8302e-02, -6.9029e-02]],\n",
       " \n",
       "          [[-2.7630e-02,  5.8793e-02, -2.1825e-02, -7.2596e-02,  4.1660e-02],\n",
       "           [-4.8410e-03, -2.7320e-02, -6.1286e-02,  2.9081e-02,  7.5358e-02],\n",
       "           [-1.2407e-02,  1.4296e-02, -1.1650e-02,  3.1181e-02,  7.7412e-02],\n",
       "           [ 3.4212e-02, -7.4276e-02,  3.3089e-02, -7.3736e-02,  2.6252e-02],\n",
       "           [-4.5341e-02,  3.0650e-02,  3.4122e-02,  5.2759e-03,  3.2493e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 7.8540e-02, -5.1411e-02, -1.1739e-02,  1.8940e-02, -3.6923e-02],\n",
       "           [-2.4312e-02,  6.4027e-02, -3.2367e-02,  5.4250e-02,  9.0724e-03],\n",
       "           [-1.7249e-02,  3.1819e-03,  1.7280e-02,  2.6000e-02, -6.5436e-02],\n",
       "           [-7.1338e-02, -1.9286e-02, -7.1022e-02, -6.4892e-02, -7.7086e-02],\n",
       "           [-2.6453e-02,  3.2084e-02, -1.4047e-02, -3.7871e-02, -6.8965e-02]],\n",
       " \n",
       "          [[-1.4233e-02, -1.9114e-02, -3.7448e-02,  4.9711e-02,  1.2441e-02],\n",
       "           [-7.0093e-02, -4.8227e-03,  1.2523e-02,  7.4140e-02,  3.8798e-02],\n",
       "           [-3.1872e-02,  3.0306e-03, -7.6752e-03, -4.5594e-02, -2.3922e-03],\n",
       "           [ 8.1002e-02,  4.2449e-02,  2.7089e-02, -2.4680e-02,  4.9074e-02],\n",
       "           [ 2.3521e-02,  3.9686e-02,  8.0853e-02,  3.3164e-02,  4.7078e-02]],\n",
       " \n",
       "          [[-8.0421e-02,  2.9489e-02, -5.5968e-02,  7.7435e-02,  6.5678e-02],\n",
       "           [-4.7000e-02,  5.0155e-02,  4.6668e-02,  4.2853e-02, -2.8486e-02],\n",
       "           [ 4.9474e-02,  7.7756e-02,  2.2752e-02, -6.1854e-02, -5.6235e-02],\n",
       "           [-2.0449e-02,  4.1137e-02, -1.3796e-02, -7.6686e-02,  4.6689e-03],\n",
       "           [ 3.3114e-02,  1.6986e-02,  3.4020e-03,  4.5275e-02,  5.5051e-02]],\n",
       " \n",
       "          [[-4.8014e-02,  2.9635e-03,  5.0353e-02, -5.4611e-02,  7.5428e-02],\n",
       "           [ 5.4521e-03,  2.0802e-02,  7.3066e-02, -6.2840e-02,  4.6026e-03],\n",
       "           [ 1.6114e-02, -3.3432e-02, -4.7390e-02, -7.1168e-02, -4.8572e-02],\n",
       "           [ 4.6566e-02,  7.9222e-02, -6.3912e-02,  1.2352e-02,  4.1915e-02],\n",
       "           [-1.5497e-02, -5.8868e-02, -3.2857e-02, -1.3696e-02,  2.1998e-02]],\n",
       " \n",
       "          [[ 2.5051e-02, -6.6268e-02, -8.3010e-03,  2.9796e-02,  5.2963e-02],\n",
       "           [-7.1763e-02, -3.8489e-02, -7.9819e-02, -1.9364e-02,  3.0093e-02],\n",
       "           [ 6.6151e-03, -7.4049e-03,  4.6867e-02,  4.9757e-03, -6.9292e-02],\n",
       "           [-7.2714e-03, -5.0587e-02,  2.9535e-02,  7.8977e-02, -7.0745e-02],\n",
       "           [-3.0113e-02, -5.2980e-02, -4.2472e-03, -1.1509e-02, -7.2331e-02]],\n",
       " \n",
       "          [[ 4.3112e-02, -6.7049e-02, -5.4057e-02,  6.2122e-02,  5.3104e-02],\n",
       "           [ 1.9700e-02,  4.1318e-03, -1.8259e-02, -4.4774e-02, -5.5062e-02],\n",
       "           [-4.4156e-02,  1.6911e-02,  3.3157e-02, -5.8204e-02,  6.7271e-02],\n",
       "           [ 4.2688e-02, -1.5858e-02, -2.3250e-02,  2.7050e-02,  1.0498e-03],\n",
       "           [ 1.3112e-02, -3.3012e-02,  6.0261e-02,  7.0331e-02,  4.8936e-02]]]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0077,  0.0349,  0.0698, -0.0423, -0.0136,  0.0368,  0.0411,  0.0569,\n",
       "          0.0053, -0.0455,  0.0787,  0.0299,  0.0635,  0.0287,  0.0278,  0.0099],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0493,  0.0288,  0.0301,  ..., -0.0409, -0.0310,  0.0077],\n",
       "         [ 0.0197,  0.0097,  0.0031,  ...,  0.0444, -0.0012,  0.0133],\n",
       "         [ 0.0438,  0.0092,  0.0275,  ...,  0.0182,  0.0027,  0.0477],\n",
       "         ...,\n",
       "         [-0.0488, -0.0242, -0.0198,  ..., -0.0355, -0.0229,  0.0442],\n",
       "         [-0.0335,  0.0005, -0.0433,  ...,  0.0090, -0.0198,  0.0242],\n",
       "         [-0.0299,  0.0202, -0.0343,  ..., -0.0485,  0.0336, -0.0255]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0281, -0.0424, -0.0345, -0.0253,  0.0458,  0.0063, -0.0007,  0.0105,\n",
       "         -0.0415,  0.0476, -0.0184, -0.0333,  0.0378,  0.0294, -0.0432,  0.0236,\n",
       "         -0.0087, -0.0051, -0.0004, -0.0190,  0.0145, -0.0377, -0.0165, -0.0135,\n",
       "         -0.0180, -0.0378, -0.0314, -0.0288,  0.0318,  0.0004, -0.0427,  0.0346,\n",
       "          0.0049, -0.0260,  0.0293, -0.0443, -0.0188,  0.0058,  0.0222, -0.0134,\n",
       "         -0.0032, -0.0464, -0.0244,  0.0066,  0.0383,  0.0095,  0.0424,  0.0390,\n",
       "          0.0022, -0.0337,  0.0336, -0.0246, -0.0498,  0.0332, -0.0222,  0.0191,\n",
       "          0.0190, -0.0458, -0.0290,  0.0204, -0.0131, -0.0183, -0.0437, -0.0024,\n",
       "          0.0276,  0.0411,  0.0325,  0.0069, -0.0268,  0.0493,  0.0144, -0.0408,\n",
       "          0.0021,  0.0490, -0.0272, -0.0078, -0.0007, -0.0236, -0.0345,  0.0246,\n",
       "          0.0444, -0.0158,  0.0201,  0.0309,  0.0495, -0.0062,  0.0227,  0.0143,\n",
       "          0.0196,  0.0380,  0.0267,  0.0324,  0.0423,  0.0470,  0.0229, -0.0198,\n",
       "          0.0300, -0.0127, -0.0389, -0.0236, -0.0296,  0.0418, -0.0262, -0.0267,\n",
       "          0.0265, -0.0201,  0.0092, -0.0335,  0.0037, -0.0388,  0.0231, -0.0231,\n",
       "          0.0165, -0.0257, -0.0403, -0.0388,  0.0444,  0.0074, -0.0211,  0.0146],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0719, -0.0874,  0.0499,  ..., -0.0890, -0.0080,  0.0536],\n",
       "         [-0.0476, -0.0139,  0.0667,  ..., -0.0895, -0.0846,  0.0136],\n",
       "         [ 0.0033, -0.0763, -0.0899,  ..., -0.0760,  0.0020, -0.0491],\n",
       "         ...,\n",
       "         [-0.0220, -0.0482, -0.0411,  ...,  0.0548, -0.0292, -0.0844],\n",
       "         [-0.0266, -0.0604, -0.0665,  ..., -0.0765,  0.0164,  0.0195],\n",
       "         [ 0.0706, -0.0849,  0.0713,  ..., -0.0018, -0.0397, -0.0165]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0659, -0.0759,  0.0811,  0.0350,  0.0836,  0.0521,  0.0612, -0.0204,\n",
       "         -0.0269, -0.0882,  0.0374,  0.0289,  0.0394, -0.0803,  0.0617,  0.0796,\n",
       "         -0.0104,  0.0743,  0.0320,  0.0215,  0.0269,  0.0563,  0.0204,  0.0206,\n",
       "          0.0800, -0.0192, -0.0137, -0.0175,  0.0149, -0.0436, -0.0414,  0.0355,\n",
       "         -0.0580,  0.0131,  0.0503,  0.0552, -0.0080,  0.0291, -0.0768,  0.0669,\n",
       "          0.0725, -0.0635,  0.0767,  0.0549,  0.0318, -0.0203, -0.0728, -0.0274,\n",
       "          0.0374, -0.0063, -0.0384, -0.0026,  0.0673, -0.0785, -0.0654, -0.0320,\n",
       "         -0.0268, -0.0757, -0.0633, -0.0564, -0.0064,  0.0020,  0.0739,  0.0293,\n",
       "          0.0183,  0.0904,  0.0085, -0.0651,  0.0851,  0.0041, -0.0157, -0.0829,\n",
       "         -0.0274,  0.0058,  0.0536, -0.0093, -0.0563,  0.0479, -0.0759, -0.0556,\n",
       "         -0.0749,  0.0781,  0.0088,  0.0251], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-5.3201e-02, -1.1942e-02, -6.4852e-02, -1.0178e-01,  3.3592e-02,\n",
       "          -2.2715e-03,  6.8014e-02,  1.0780e-01,  4.1177e-02, -1.0306e-01,\n",
       "          -6.1484e-02,  8.2535e-03, -1.4804e-02,  2.3537e-02, -4.7694e-02,\n",
       "           6.7412e-03, -8.6845e-02, -7.7079e-02, -4.1279e-03,  5.8004e-02,\n",
       "          -6.4952e-02,  1.9175e-02, -4.3850e-02,  1.0240e-02, -3.7335e-03,\n",
       "          -7.8731e-02,  3.3510e-02, -7.9369e-02, -1.9637e-02, -1.2560e-02,\n",
       "           7.8992e-02,  9.1594e-03,  1.4050e-02, -1.0662e-01,  5.2233e-02,\n",
       "          -1.0648e-01, -1.0745e-01, -1.0466e-01,  1.0763e-01, -3.9471e-02,\n",
       "          -5.9130e-02,  6.1545e-02,  7.5499e-02,  7.2721e-02, -3.0432e-02,\n",
       "          -8.6025e-02,  3.5392e-02,  5.6423e-03,  5.5532e-02, -7.1069e-03,\n",
       "           1.0805e-02, -8.4392e-02,  4.0910e-02,  3.6046e-02,  1.0747e-01,\n",
       "           2.3651e-02,  2.5842e-02,  9.2636e-02, -1.0178e-01,  7.3537e-02,\n",
       "          -2.6282e-02,  2.3123e-03,  3.3214e-02, -1.0737e-01,  1.3081e-02,\n",
       "           1.0640e-01, -9.4176e-02, -1.1271e-02, -7.0685e-02,  1.8735e-02,\n",
       "           9.2468e-02,  8.3127e-02, -7.9660e-03,  7.7240e-02, -3.4273e-02,\n",
       "           3.7550e-02, -8.2841e-02, -1.0350e-01,  6.2759e-02,  1.7890e-02,\n",
       "          -5.8767e-02,  1.2739e-02,  8.5216e-02,  9.1343e-02],\n",
       "         [ 4.1530e-02,  4.1940e-02, -1.9912e-03,  1.0848e-01,  3.4984e-02,\n",
       "          -2.9243e-02, -8.6538e-02, -3.9535e-02,  9.7859e-02, -2.1700e-03,\n",
       "           4.3296e-02,  6.4582e-02,  9.4597e-02, -2.7424e-02, -1.0642e-01,\n",
       "          -2.8097e-02, -7.5926e-02,  9.6511e-02, -3.5196e-02,  1.7196e-02,\n",
       "           4.3638e-02,  6.3218e-02, -1.2781e-02,  3.4692e-02,  3.9064e-02,\n",
       "          -6.8423e-02, -6.7037e-04,  9.5388e-02, -4.3061e-02,  7.9978e-02,\n",
       "           1.5020e-02,  1.4352e-02,  3.7708e-02,  4.8826e-02,  2.9729e-02,\n",
       "          -3.5330e-02,  2.0856e-02, -7.8222e-03,  8.1298e-02,  5.5409e-03,\n",
       "           5.5566e-02, -4.0743e-03,  1.0639e-02,  7.4008e-02,  1.3052e-02,\n",
       "          -8.2406e-02, -7.4906e-02, -3.4545e-02, -3.9429e-02, -4.9347e-02,\n",
       "          -3.9651e-02, -5.7336e-03, -5.8944e-02,  5.6181e-02,  7.1036e-02,\n",
       "           9.3440e-02, -3.0842e-02, -8.5635e-02,  6.9143e-02,  4.0791e-02,\n",
       "           2.7898e-03, -9.7871e-02, -8.7494e-02, -4.1720e-02, -9.9195e-02,\n",
       "           4.3958e-02,  4.9593e-02,  7.1965e-03, -1.8051e-02,  2.4889e-02,\n",
       "          -9.0718e-02, -3.6701e-02,  2.8471e-03,  7.1715e-02, -8.9015e-02,\n",
       "           9.0259e-02,  7.4086e-02, -5.6744e-02,  2.7528e-02,  4.3565e-02,\n",
       "          -2.3187e-02,  8.5824e-02,  1.0804e-01,  2.0232e-02],\n",
       "         [ 9.6949e-03, -9.8812e-02,  3.9063e-02,  9.5963e-02, -2.6368e-02,\n",
       "          -9.3620e-02, -4.9392e-02,  2.7380e-02, -9.7316e-02, -8.5835e-02,\n",
       "          -2.9165e-02, -7.9730e-02, -1.3869e-02,  5.0461e-02, -7.3402e-02,\n",
       "          -2.2913e-02, -6.4951e-02,  9.0270e-02, -5.9305e-02, -5.1772e-02,\n",
       "           6.2654e-02,  3.0857e-02,  1.9329e-03, -8.0823e-02, -9.7266e-04,\n",
       "          -2.8373e-02, -1.6847e-02,  2.1261e-03, -7.0912e-02, -4.1933e-02,\n",
       "          -9.5666e-02,  2.2711e-02,  3.4295e-02,  3.6928e-02,  3.7569e-02,\n",
       "           2.0322e-03, -2.9445e-02,  5.4848e-02,  7.9279e-03,  4.9298e-02,\n",
       "          -8.1097e-02,  9.5512e-02, -6.4082e-02,  1.0710e-01, -2.3144e-02,\n",
       "          -3.1707e-03, -3.3008e-02,  3.2828e-02,  6.4682e-03,  7.0758e-02,\n",
       "           8.1698e-02, -6.7604e-02, -5.6342e-02,  9.9714e-03, -6.5634e-02,\n",
       "           9.0989e-02,  6.9489e-02, -3.5026e-02, -1.8651e-02, -3.7700e-02,\n",
       "          -3.5923e-02,  8.0326e-03, -7.2150e-02,  8.9943e-02,  8.7581e-02,\n",
       "          -1.0165e-01, -7.5979e-02, -3.2422e-02,  6.6794e-02, -1.2968e-02,\n",
       "          -3.3211e-02,  5.2241e-02,  1.3163e-02,  9.8850e-02, -6.9592e-02,\n",
       "           4.5297e-02,  7.1869e-02, -8.6704e-03, -4.4876e-03, -8.6751e-02,\n",
       "           7.8185e-02,  6.9900e-02, -1.0751e-01, -3.8964e-03],\n",
       "         [ 9.3300e-02,  8.7678e-02,  5.8525e-02,  1.7067e-02, -7.5651e-02,\n",
       "          -5.5029e-02,  9.4550e-02,  1.5302e-02,  7.9594e-03,  6.1826e-02,\n",
       "          -7.0838e-02, -5.0113e-02, -8.0114e-02, -5.7247e-02,  3.2163e-02,\n",
       "          -1.0600e-01, -8.8483e-02,  1.3440e-02,  6.5005e-02, -5.7275e-02,\n",
       "           7.4279e-02, -1.0443e-01,  9.1655e-02, -3.1030e-03, -6.5398e-02,\n",
       "           6.4014e-02, -4.1968e-02, -5.6143e-02,  8.9789e-02,  5.6133e-02,\n",
       "          -9.5652e-02,  4.6140e-02, -9.2939e-02, -7.0524e-02, -4.6774e-02,\n",
       "           2.1886e-02, -6.0354e-02,  5.8372e-02,  8.6471e-02,  1.0036e-01,\n",
       "          -2.4825e-02,  7.0304e-02, -7.7000e-02, -5.9475e-02,  9.1391e-02,\n",
       "          -3.7595e-02,  3.0457e-02,  5.0527e-02,  8.8604e-02,  7.4111e-02,\n",
       "           3.8718e-02, -8.8082e-03,  1.1661e-02,  1.3238e-02,  8.2973e-02,\n",
       "           2.9743e-02, -9.3399e-02, -7.1979e-02, -4.9832e-02,  5.0644e-02,\n",
       "          -9.7155e-02, -5.2304e-02, -6.3009e-03, -6.1097e-02, -7.2711e-02,\n",
       "           6.7129e-02, -5.1013e-02, -9.8346e-02,  2.9600e-02, -3.7685e-02,\n",
       "           5.6878e-02,  2.9185e-02, -6.7211e-02, -5.8221e-02, -7.7920e-02,\n",
       "          -2.3029e-02, -5.9008e-03,  2.2670e-02, -7.9744e-02,  3.5887e-02,\n",
       "          -3.5822e-02,  1.0469e-01,  7.0239e-02,  7.2325e-02],\n",
       "         [ 6.6587e-03,  6.1688e-02,  8.4766e-03,  3.5270e-02,  8.1286e-02,\n",
       "          -9.8034e-02, -9.5818e-02,  8.6357e-02, -4.1306e-02,  9.3075e-02,\n",
       "          -9.2373e-02,  1.2410e-02,  6.7617e-02,  8.6109e-02, -8.6370e-02,\n",
       "          -6.4281e-02, -5.5705e-02,  6.5988e-02,  5.3913e-02, -7.2066e-02,\n",
       "          -1.2159e-02,  7.7598e-02,  7.3248e-02,  1.0618e-01, -7.5359e-02,\n",
       "           7.2302e-02, -3.2136e-03, -1.0257e-01, -3.5790e-02,  1.0553e-01,\n",
       "          -9.0892e-02, -9.0023e-02,  3.8872e-02, -8.3020e-02, -3.2848e-03,\n",
       "          -9.9750e-02,  6.7106e-03, -4.4765e-02, -3.7183e-02,  6.8971e-02,\n",
       "          -5.3732e-02, -4.5488e-02, -5.7057e-02,  2.1145e-02, -2.6242e-02,\n",
       "           1.0698e-01,  8.8914e-02, -9.2292e-02, -4.1582e-03, -8.2253e-02,\n",
       "          -5.0138e-02, -7.6851e-02,  9.5835e-02,  1.0641e-02, -5.4468e-02,\n",
       "          -1.0403e-01,  5.3000e-02, -9.6266e-02,  8.1546e-02,  7.1358e-02,\n",
       "          -7.5068e-02, -9.5404e-02, -2.9315e-02, -9.4265e-02, -7.3562e-02,\n",
       "          -9.9638e-02,  7.4792e-03, -9.0570e-02,  3.8618e-03, -6.0340e-02,\n",
       "           7.0967e-03, -5.3714e-02, -3.2884e-02, -2.0451e-02, -1.2098e-02,\n",
       "           2.2902e-02, -8.7329e-02, -1.0149e-01, -6.7432e-02, -7.1453e-02,\n",
       "          -9.9789e-03, -1.0421e-01, -7.4880e-02, -1.0897e-01],\n",
       "         [ 6.4504e-03,  5.1962e-02, -7.2476e-02,  9.3607e-02, -9.6248e-03,\n",
       "           2.6432e-02, -2.5636e-02,  6.3009e-02,  7.7865e-02,  4.4414e-03,\n",
       "          -1.7319e-02, -4.1416e-02, -1.0076e-01, -1.0657e-01, -3.8772e-03,\n",
       "          -3.7422e-02,  9.7387e-02, -7.6447e-03, -7.9105e-02,  8.5707e-02,\n",
       "           7.1795e-02,  7.6401e-02,  4.0097e-02,  6.0516e-02,  3.6421e-02,\n",
       "           5.7619e-02, -6.9906e-02,  3.2779e-02, -3.3487e-02, -1.0558e-02,\n",
       "           9.7479e-02,  9.1711e-02,  1.0090e-01, -5.9671e-02,  6.4883e-02,\n",
       "           3.7938e-02, -9.1662e-02,  3.8948e-02,  4.1982e-02, -7.9845e-02,\n",
       "          -5.6520e-02, -1.0735e-01,  1.2235e-02,  1.7699e-02,  1.6478e-02,\n",
       "          -8.7708e-02, -6.7750e-02, -4.9360e-02, -8.0654e-02, -5.5831e-02,\n",
       "           5.1334e-02,  1.0505e-01, -6.8885e-02,  9.2038e-02, -7.8745e-05,\n",
       "           9.1564e-02, -6.6656e-02,  6.5681e-02,  1.0222e-01,  7.8668e-02,\n",
       "           1.0894e-01,  7.0001e-02,  8.3981e-02, -7.4333e-02,  3.8678e-02,\n",
       "           9.4733e-02, -1.6865e-02,  7.4686e-03, -4.9133e-03,  3.7951e-02,\n",
       "          -3.7631e-02, -9.7281e-04,  2.4495e-02, -6.4087e-02, -8.9067e-02,\n",
       "           7.5992e-02, -5.7436e-02, -8.5367e-02, -3.1654e-02,  9.2340e-02,\n",
       "           9.4182e-02, -1.2938e-02, -4.6170e-02, -8.0765e-02],\n",
       "         [ 8.5223e-03,  1.0543e-01,  9.8783e-02, -3.1092e-02, -6.7140e-02,\n",
       "          -3.5890e-02, -4.3221e-03, -1.0359e-01, -1.7018e-02,  1.3027e-02,\n",
       "          -2.3269e-02, -9.9859e-02, -9.9167e-02,  4.3684e-02,  6.4568e-02,\n",
       "           8.6987e-02, -6.2507e-02,  7.8532e-02, -5.3430e-02, -8.2266e-02,\n",
       "          -7.0880e-02,  3.4875e-02, -3.0562e-03, -9.4624e-02,  5.5331e-02,\n",
       "           7.7993e-02,  3.5160e-02, -8.8902e-02, -7.0539e-02, -6.5613e-02,\n",
       "           7.3504e-02,  3.9832e-02,  3.9177e-02, -7.9095e-02, -1.3444e-02,\n",
       "           9.2038e-02,  2.5405e-03,  4.0927e-02,  1.0240e-01,  5.5746e-02,\n",
       "           9.8819e-03, -2.9178e-02,  5.1487e-02, -1.9530e-02,  9.2565e-02,\n",
       "          -9.7272e-02,  3.0202e-03,  7.3816e-03,  8.7579e-02, -9.8380e-02,\n",
       "           9.0603e-02,  5.8704e-02, -1.0291e-02,  1.0616e-01, -5.3442e-02,\n",
       "          -6.4915e-02,  1.0643e-01, -6.1287e-02, -6.4252e-02, -6.8457e-02,\n",
       "           1.0631e-01,  2.4221e-02,  9.9240e-02,  5.9132e-02,  9.0352e-02,\n",
       "          -9.1225e-02, -5.2533e-02, -9.1444e-02, -4.2864e-02,  3.9205e-02,\n",
       "          -1.9359e-02, -9.2431e-02, -6.1777e-03,  7.1824e-02, -1.0577e-01,\n",
       "           9.2852e-02, -6.4502e-03, -7.0085e-03,  6.2508e-02, -7.4974e-02,\n",
       "          -1.0067e-02,  5.2864e-02, -9.9179e-02, -6.3670e-02],\n",
       "         [-8.7197e-02,  4.0513e-02, -3.0043e-02,  9.3835e-02, -3.6271e-02,\n",
       "          -3.9425e-03, -6.8609e-02,  4.1238e-03,  6.4464e-02,  8.2983e-02,\n",
       "          -5.3319e-02, -7.5157e-02, -2.7845e-02,  1.6525e-03, -9.5783e-03,\n",
       "           9.8632e-04,  4.3776e-02,  7.6159e-02,  7.8011e-02,  4.7361e-02,\n",
       "           1.0698e-01, -1.0532e-01, -1.5111e-02, -8.7060e-02,  1.3925e-02,\n",
       "          -2.1726e-02, -2.4274e-02,  1.2165e-02, -6.4262e-02, -9.3424e-02,\n",
       "          -1.3781e-02, -1.0531e-01,  1.3076e-03, -7.2995e-02,  1.0571e-01,\n",
       "           2.2131e-02, -6.1613e-02,  5.2313e-02, -4.1732e-02,  7.1259e-02,\n",
       "          -6.3937e-02,  3.9316e-02,  3.2933e-02, -2.4662e-02,  6.2911e-02,\n",
       "          -6.1873e-02, -6.3401e-02,  7.6733e-02, -1.0301e-01,  4.1076e-02,\n",
       "          -3.8968e-02, -6.8362e-02,  6.7133e-02,  9.1307e-02,  8.1159e-02,\n",
       "          -9.5602e-02,  6.1885e-02,  6.7038e-02, -2.2223e-03, -8.1936e-02,\n",
       "          -5.5927e-02,  3.1606e-02, -9.2450e-02,  1.9389e-02,  4.4972e-02,\n",
       "           1.0122e-01,  9.3621e-02,  1.6857e-02, -5.1679e-02, -2.6006e-02,\n",
       "           6.1061e-02, -9.7397e-02, -9.7872e-02, -4.8807e-02,  5.5834e-02,\n",
       "          -7.7039e-02,  5.7240e-02, -1.3703e-03,  1.3018e-03, -3.8357e-02,\n",
       "          -8.5558e-02,  1.1583e-02, -1.2643e-02, -1.0465e-01],\n",
       "         [ 6.3846e-02, -9.8633e-02, -1.0380e-01,  1.0855e-01, -9.2072e-02,\n",
       "          -6.3527e-02, -9.9600e-02, -1.0795e-01, -7.0778e-02, -9.6360e-02,\n",
       "          -6.1721e-03,  7.9703e-02,  4.7682e-02,  3.4180e-03, -5.4676e-02,\n",
       "          -1.0025e-01,  1.0120e-01,  1.7545e-02,  9.4151e-02, -5.7722e-03,\n",
       "           7.4416e-02, -7.7300e-02, -9.3867e-03,  1.3017e-02,  8.1404e-02,\n",
       "           7.6389e-03,  1.8435e-02,  6.2736e-02,  2.7798e-02, -1.9057e-02,\n",
       "           8.3172e-02,  4.4709e-03, -4.5592e-02, -8.0352e-02,  4.6167e-02,\n",
       "          -1.0332e-01, -5.4554e-02, -3.9389e-02, -6.5383e-02,  5.1661e-02,\n",
       "          -2.0107e-02, -1.4352e-02, -6.1517e-02, -5.7923e-02, -5.0205e-02,\n",
       "          -8.4849e-02,  1.0774e-01, -1.0695e-01, -6.1930e-03,  4.5879e-02,\n",
       "          -4.8976e-02,  8.6547e-02, -8.1476e-02, -3.3147e-02, -1.0827e-01,\n",
       "          -2.2280e-02, -6.8073e-02,  9.8064e-02,  9.4900e-02, -3.8633e-02,\n",
       "           5.0414e-02,  1.1595e-02,  5.3072e-02, -8.8827e-02,  1.0256e-02,\n",
       "           4.7293e-02, -6.8326e-02,  3.0689e-02,  7.7023e-03, -3.9836e-02,\n",
       "          -7.7172e-02, -8.0015e-02, -8.3019e-03, -1.0237e-01,  7.2244e-02,\n",
       "          -5.3826e-02,  6.7162e-02,  5.8323e-02,  1.0201e-01, -5.1489e-02,\n",
       "           4.1366e-02,  1.0613e-01,  6.5160e-02, -1.0085e-01],\n",
       "         [-9.0403e-02,  7.7144e-02,  1.0887e-01,  1.0844e-01,  1.0228e-01,\n",
       "          -1.2615e-02, -1.0452e-01,  6.4561e-02,  2.8394e-02,  2.4750e-02,\n",
       "           6.8127e-02, -6.2688e-02,  1.0125e-01,  9.7713e-03,  7.1993e-02,\n",
       "          -8.4092e-02,  1.0320e-03,  7.5475e-02, -4.8509e-02,  9.8071e-03,\n",
       "          -2.1533e-03,  9.0844e-03,  8.4141e-02,  8.5431e-02, -7.9795e-02,\n",
       "          -7.7699e-02,  4.6865e-02, -6.5483e-02,  6.8056e-02,  6.5958e-02,\n",
       "          -2.6651e-02, -8.0648e-02, -2.8785e-02,  9.1529e-02, -1.0902e-02,\n",
       "          -6.7606e-02, -5.8009e-04,  6.3362e-02,  5.5690e-02,  8.1296e-02,\n",
       "           9.0304e-03, -5.3235e-02,  1.5770e-02,  1.0709e-01,  3.6035e-02,\n",
       "           9.5382e-02, -1.7537e-02, -4.1339e-02, -1.4252e-02, -4.6402e-03,\n",
       "           5.6035e-02, -5.6226e-02,  8.1780e-02,  7.3679e-02, -8.8337e-02,\n",
       "           7.6147e-02,  1.8744e-02, -8.6294e-02,  9.1398e-02, -7.8472e-02,\n",
       "           8.8783e-02,  2.7236e-02,  1.4125e-02,  5.7870e-02, -6.9838e-02,\n",
       "           1.0478e-01,  9.4555e-03,  7.4708e-02,  1.3839e-03, -1.5857e-02,\n",
       "          -8.9058e-02,  1.0284e-01,  7.1875e-02, -1.0609e-01, -3.2861e-02,\n",
       "           7.3623e-02, -2.0974e-02,  1.3278e-02,  6.2045e-02, -1.2037e-02,\n",
       "           2.1258e-02,  6.5712e-02,  2.2390e-02, -5.8883e-02]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0321, -0.0774, -0.0116,  0.0011,  0.0205, -0.0321, -0.0661, -0.0112,\n",
       "         -0.0030, -0.0908], requires_grad=True)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = list(net.parameters())# 返回学习参数\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 1, 5, 5])\n",
      "conv1.bias : torch.Size([6])\n",
      "conv2.weight : torch.Size([16, 6, 5, 5])\n",
      "conv2.bias : torch.Size([16])\n",
      "fc1.weight : torch.Size([120, 400])\n",
      "fc1.bias : torch.Size([120])\n",
      "fc2.weight : torch.Size([84, 120])\n",
      "fc2.bias : torch.Size([84])\n",
      "fc3.weight : torch.Size([10, 84])\n",
      "fc3.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name,p  in net.named_parameters():\n",
    "    print(name,':',p.size())# 返回学习参数和名称\n",
    "#     print(list(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0430, -0.0452, -0.0567, -0.0107, -0.0002, -0.0256, -0.0959, -0.0213,\n",
      "         -0.0013, -0.0513]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#forward 的输入输出都是Variable，需要把Tensor转换为Variable\n",
    "input = Variable(t.randn(1,1,32,32))\n",
    "out = net(input)\n",
    "out.size()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad() #所有参数清零\n",
    "out.backward(Variable(t.ones(1,10)))#反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch一次必须是一个batch。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
